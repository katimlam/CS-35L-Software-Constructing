<!doctype html
	public "-//w3c//dtd html 4.01//en"
	"http://www.w3.org/tr/html4/strict.dtd">
<html>
<head>
<meta http-equiv='content-type' content='text/html;charset=utf-8'>
<title>assignment 2. shell scripting</title>
</head>

<body>

<h1>assignment 2. shell scripting</h1>

<h2>laboratory: spell-checking hawaiian</h2>

<p>keep a log in the file <samp>lab2.log</samp> of what you do in the
lab so that you can reproduce the results later. this should not
merely be a transcript of what you typed: it should be more like a
true lab notebook, in which you briefly note down what you did and
what happened.</p>

<p>for this laboratory we assume you're in the standard c or <a
href='http://en.wikipedia.org/wiki/posix'>posix</a> <a
href='http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/v1_chap07.html#tag_07'>locale</a>. the
shell command <a
href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/locale.html'><samp>locale</samp></a>
should output <samp>lc_ctype="c"</samp>
or <samp>lc_ctype="posix"</samp>. if it doesn't, use the following
shell command:</p>

<pre><samp><a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/v3_chap02.html#export'>export</a> lc_all='c'
</samp></pre>

<p>and make sure <samp>locale</samp> outputs the right thing afterwards.</p>

<p>we also assume the file <samp>words</samp> contains a sorted list of
english words. create such a file by sorting the contents of the file
<samp>/usr/share/dict/words</samp> on the seasnet gnu/linux hosts, and putting
the result into a file named <samp>words</samp> in your working
directory. to do that, you can use
the <samp><a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/sort.html'>sort</a></samp>
command.</p>

<p>then, take a text file containing the html in this
assignment's web page, and run the following commands with that
text file being standard input. describe generally what each command
outputs (in particular, how its output differs from that of the
previous command), and why.</p>

<pre><samp>tr -c 'a-za-z' '[\n*]'
tr -cs 'a-za-z' '[\n*]'
tr -cs 'a-za-z' '[\n*]' | sort
tr -cs 'a-za-z' '[\n*]' | sort -u
tr -cs 'a-za-z' '[\n*]' | sort -u | comm - words
tr -cs 'a-za-z' '[\n*]' | sort -u | comm -23 - words
</samp></pre>

<p>let's take the last command as the crude implementation of an
english spelling checker. suppose we want to change it to be a
spelling checker for
<a href='http://en.wikipedia.org/wiki/hawaiian_language'>hawaiian</a>,
a language whose traditional orthography
has only the following
letters (or their capitalized equivalents):</p>

<pre><samp>p k ' m n w l h a e i o u
</samp></pre>

<p>in this lab for convenience we use ascii apostrophe (') to
represent the hawaiian &#8216;okina (&#8216;); it has no capitalized
equivalent.</p>

<p>create in the file <samp>hwords</samp> a simple hawaiian
dictionary containing a copy of all the hawaiian words in
the tables in
"<a href='http://mauimapp.com/moolelo/hwnwdseng.htm'>english to hawaiian</a>", an introductory list of words.
use <a href='http://www.gnu.org/software/wget/'>wget</a> to obtain
your copy of that web page.
extract these words systematically from the tables in "english to hawaiian". assume that each occurrence of "<samp>&lt;tr&gt; &lt;td&gt;<var>eword</var>&lt;/td&gt; &lt;td&gt;<var>hword</var>&lt;/td&gt;</samp>" contains a hawaiian word
in the <samp><var>hword</var></samp> position. treat upper case
letters as if they were lower case; treat
"<samp>&lt;u&gt;a&lt;/u&gt;</samp>" as if it were "<samp>a</samp>",
and similarly for other letters; and treat
<samp>`</samp> (ascii grave accent) as if it were <samp>'</samp>
(ascii apostrophe, which we use to represent &#8216;okina).
some entries, for example "<samp>h&lt;u&gt;a&lt;/u&gt;lau, kula</samp>", contain
spaces or commas; treat them as multiple words (in this case, as
"<samp>halau</samp>" and "<samp>kula</samp>"). you may find that some of the
entries are improperly formatted and contain english rather than
hawaiian; to fix this problem reject any entries that contain
non-hawaiian letters after the abovementioned substitutions are
performed. sort the resulting list of words, removing any duplicates.
do not attempt to repair any remaining problems by hand; just use the
systematic rules mentioned above. automate the systematic rules
into a shell script <samp>buildwords</samp>, which you should copy into your
log; it should read the html from standard input and write a sorted list of
unique words to standard output.  for example, we should be able to run this
script with a command like this:</p>

<pre><samp>cat foo.html bar.html | ./buildwords | less
</samp></pre>

<p>if the shell script has bugs and
doesn't do all the work, your log should record in detail each bug
it has.</p>

<p>modify the last shell command shown above so that it checks the
spelling of hawaiian rather than english, under the assumption
that <samp>hwords</samp> is a hawaiian dictionary. input that
is upper case should be lower-cased before it is checked against the
dictionary, since the dictionary is in all lower case.</p>

<p>check your work by running your hawaiian spelling checker on
this web page (which you should also fetch with wget), and on the
hawaiian dictionary <samp>hwords</samp> itself. count the
number of "misspelled" english and hawaiian words on this web
page, using your spelling checkers. are there any words that are
"misspelled" as english, but not as hawaiian? or "misspelled"
as hawaiian but not as english? if so, give examples.</p>

<h2>homework: find duplicate files</h2>

<p>suppose you're working in a project where software (or people)
create lots of files, many of them duplicates. you don't want the
duplicates: you want just one copy of each, to save disk space. write
a shell script <samp>sameln</samp> that takes a single argument naming
a directory d, finds all regular files immediately under d that are
duplicates, and replaces the duplicates
with <a href='http://en.wikipedia.org/wiki/hard_link'>hard
links</a>. your script should not recursively examine all files that
are in subdirectories of d; it should examine only files that are
immediately in d.</p>

<p>if your script finds two or more files that are duplicates, it
should keep the file whose name is lexicographically first (for
example, if the duplicates are named x, a, and b, it should keep a and
replace x and b with hard links to a); however, it should prefer files
whose name start with "." to other files (for example, if the
duplicates are named .y, .x, a, and b, it should keep .x and replace
the others with hard links to .x).</p>

<p>if your script finds a file in d that is not a regular file, it
should silently ignore it; for example, it should silently ignore all
symbolic links and directories. if your script has a problem reading a
file (for example, if the file not readable to you), it should report
the error and not treat it as a duplicate of any file.</p>

<p>you need not worry about the cases where your script is given no
arguments, or more than one argument.  however, be prepared to handle
files whose names contain special characters like spaces, "*", and
leading "&ndash;".</p>

<p>your script should be runnable as an ordinary user, and should be
portable to any system that supports the
<a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/toc.html'>standard
posix shell and utilities</a>; please see
its <a href='http://pubs.opengroup.org/onlinepubs/9699919799/idx/utilities.html'>list
of utilities</a> for the commands that your script may use. hint: see
the <a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/cmp.html'><samp>cmp</samp></a>,
<a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/ln.html'>ln</a>,
and <a href='http://pubs.opengroup.org/onlinepubs/9699919799/utilities/test.html'>test</a>
utilities.</p>

<h2>submit</h2>

<p>submit the following files.</p>

<ul>

<li>the script <samp>buildwords</samp> as described in the lab.</li>

<li>the file <samp>lab2.log</samp> as described in the lab.</li>

<li>the file <samp>sameln</samp> as described in the homework.</li>
</ul>

<p>all files should be ascii text files, with no
carriage returns, and with no more than 80 columns per line. the shell
command:</p>

<pre><samp>awk '/\r/ || 80 &lt; length' lab2.log sameln
</samp></pre>

<p>should output nothing.</p>


<hr>
<address>
 &copy; 2005, 2007, 2008, 2010, 2013 <a href='../mail-eggert.html'>paul eggert</a>
 and steve vandebogart.
 &copy; 2007 paul eggert.
 see <a href='../copyright.html'>copying rules</a>.<br>

 $id: assign2.html,v 1.29 2013/04/08 16:46:24 eggert exp $

</address>

</body>
</html>
